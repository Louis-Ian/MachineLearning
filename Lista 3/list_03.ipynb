{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Questão 1`\n",
    "Considere o conjunto de dados disponível em kc2.csv, organizado em 22 colunas, sendo as 21 primeiras colunas os atributos e a última coluna a saída. Os 21 atributos são referentes à caracterização de códigos-fontes para processamento de dados na NASA. A saída é a indicação de ausência (0) ou existência (1) de defeitos (os dados foram balanceados via subamostragem). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/search?type=data&sort=runs&id=1063&status=active.\n",
    "\n",
    "A) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "\n",
    "- **KNN** (escolha k = 1 e k = 5, distância Euclidiana e Mahalonobis, totalizando 4 combinações);\n",
    "- **Árvore de decisão** (você pode usar uma implementação já existente com índices de impureza de gini e entropia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 22)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc2_dataset = np.loadtxt('kc2.csv', delimiter=',')\n",
    "kc2_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 21)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_kc2_dataset = kc2_dataset[:, :-1]\n",
    "x_kc2_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 1)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_kc2_dataset = kc2_dataset[:, [-1]]\n",
    "y_kc2_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_split(x: np.ndarray, y: np.ndarray, n_partitions: int):\n",
    "    k_folds = []\n",
    "    xy = np.random.permutation(np.hstack((x, y)))\n",
    "\n",
    "    # every fold gets the rounded down number of: number of samples / number of partitions\n",
    "    for i in range(n_partitions):\n",
    "        k_folds.append(xy[i*(xy.shape[0] // n_partitions) : (i+1)*(xy.shape[0] // n_partitions), :])\n",
    "\n",
    "    # The remaining samples get distributed between the first folds, one each\n",
    "    if(x.shape[0] % n_partitions > 0):\n",
    "        for i in range(x.shape[0] % n_partitions):\n",
    "            k_folds[i] = np.vstack((k_folds[i], xy[[-(i + 1)], :]))\n",
    "\n",
    "    return np.array(k_folds, dtype=\"object\")\n",
    "\n",
    "def kfold_even_split(x: np.ndarray, y: np.ndarray, n_partitions: int):\n",
    "    k_folds = []\n",
    "    xy = np.random.permutation(np.hstack((x, y)))\n",
    "\n",
    "    # every fold gets the rounded down number of: number of samples / number of partitions\n",
    "    for i in range(n_partitions):\n",
    "        k_folds.append(xy[i*(xy.shape[0] // n_partitions) : (i+1)*(xy.shape[0] // n_partitions), :])\n",
    "\n",
    "    return np.array(k_folds, dtype=\"object\")\n",
    "\n",
    "def loo_split(x: np.ndarray, y: np.ndarray):\n",
    "    return kfold_split(x, y, x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_normalize(x: np.ndarray, y: np.ndarray):\n",
    "    epsilon = 1e-15\n",
    "\n",
    "    x_columns_max = x.max(axis=0, keepdims=True)\n",
    "    ymax = y.max()\n",
    "    \n",
    "    x_columns_min = x.min(axis=0, keepdims=True)\n",
    "    ymin = y.min()\n",
    "\n",
    "    x = (x - x_columns_min) / (x_columns_max - x_columns_min + epsilon)\n",
    "    y = (y - ymin) / (ymax - ymin)\n",
    "\n",
    "    # Values that will be needed for denormalization\n",
    "    xscale_tuple = (x_columns_max - x_columns_min, x_columns_min + epsilon)\n",
    "    yscale_tuple = (ymax - ymin, ymin)\n",
    "    \n",
    "    return x, y, xscale_tuple, yscale_tuple\n",
    "\n",
    "def normalize_with_scale(x: np.ndarray, x_scale: Tuple[float, float]):\n",
    "    return (x - x_scale[0]) / x_scale[1]\n",
    "\n",
    "def minmax_denormalize(x: np.ndarray, y: np.ndarray, xscale: Tuple[np.ndarray, np.ndarray], yscale: Tuple[float, float]):\n",
    "    y = y * yscale[0] + yscale[1]\n",
    "    x = x * xscale[0] + xscale[1]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distances(x: np.ndarray, y: np.ndarray, datapoint: np.ndarray):\n",
    "    # if(datapoint.shape[0] > 1):\n",
    "    #     datapoint_distances = []\n",
    "\n",
    "    #     for line in datapoint:\n",
    "    #         datapoint_distances.append((((x - line.reshape(1, -1))**2).sum(1))**0.5)\n",
    "        \n",
    "        # return np.array(datapoint_distances, dtype=\"object\")\n",
    "            \n",
    "    # else:\n",
    "        return (((x - datapoint)**2).sum(1))**0.5\n",
    "\n",
    "def manhattam_distances(x: np.ndarray, y: np.ndarray, datapoint: np.ndarray):\n",
    "    pass\n",
    "\n",
    "def minkowski_distances(x: np.ndarray, y: np.ndarray, datapoint: np.ndarray):\n",
    "    pass\n",
    "\n",
    "def mahalanobis_distances(x: np.ndarray, y: np.ndarray, datapoint: np.ndarray):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(x: np.ndarray, y: np.ndarray, k: int, dist_func: Callable[[np.ndarray, np.ndarray, np.ndarray], np.ndarray], datapoints: np.ndarray):\n",
    "    # \n",
    "    y_datapoints = datapoints[:, [-1]]\n",
    "    datapoints = datapoints[:, :-1]\n",
    "\n",
    "    # normalize data\n",
    "    x_normalized, y_normalized, x_scale, y_scale = minmax_normalize(x, y)\n",
    "\n",
    "    # calculate distances\n",
    "    datapoints_distances = []\n",
    "\n",
    "    for line in datapoints:\n",
    "        datapoints_distances.append(\n",
    "            np.hstack((dist_func(x_normalized, y_normalized, normalize_with_scale(line, x_scale)).reshape(-1, 1),\n",
    "                       y))\n",
    "            )\n",
    "    \n",
    "    datapoints_distances = np.array(datapoints_distances, dtype='float64')\n",
    "    pred_classes = np.zeros((datapoints.shape[0], 2))\n",
    "\n",
    "    for i, line in enumerate(datapoints_distances):\n",
    "        # sort by nearest neighbour\n",
    "        sorted_indices = np.argsort(line[:, 0])\n",
    "        sorted_datapoint = line[sorted_indices]\n",
    "\n",
    "        sorted_distances = sorted_datapoint[:, 0]\n",
    "        sorted_classes = np.array(sorted_datapoint[:, 1], dtype='int64')\n",
    "\n",
    "        # calculate predicted class\n",
    "        k_nearest_classes = sorted_classes[:k]\n",
    "        pred_class = np.bincount(k_nearest_classes).argmax()\n",
    "        pred_classes[i] = [pred_class.flatten(), y_datapoints.flatten()[i]]\n",
    "        # pred_classes.append([pred_class, y_datapoints.flatten[i]])\n",
    "    \n",
    "    return pred_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "\n",
    "- ### **KNN** (escolha k = 1 e k = 5, distância Euclidiana e Mahalonobis, totalizando 4 combinações);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 21, 22)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc2_dataset_kfolds = kfold_even_split(x_kc2_dataset, y_kc2_dataset, 10)\n",
    "kc2_dataset_kfolds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n",
      "(21, 22)\n"
     ]
    }
   ],
   "source": [
    "for each in kc2_dataset_kfolds:\n",
    "    print(each.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y: np.ndarray, pred:np.ndarray):\n",
    "\n",
    "    true_pos = ((y==1) & (pred == 1)).sum()\n",
    "    true_neg = ((y==0) & (pred == 0)).sum()\n",
    "    false_pos = ((y==0) & (pred == 1)).sum()\n",
    "    false_neg = ((y==1) & (pred == 0)).sum()\n",
    "    global_acc = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "    class1_acc = true_pos / (true_pos + false_pos)\n",
    "    class2_acc = true_neg / (true_neg + false_neg)\n",
    "    precision = true_pos / (true_pos + false_neg)\n",
    "    revoke = true_pos / (true_pos + false_pos)\n",
    "\n",
    "    return global_acc, class1_acc, class2_acc, precision, revoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1\n",
      "STATS - fold 0\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 1.0\n",
      "class 2 acc: 0.0\n",
      "precision: 0.0\n",
      "revoke: 0.0\n",
      "\n",
      "\n",
      "STATS - fold 1\n",
      "\n",
      "global acc: 0.47619047619047616\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 2\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 3\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 4\n",
      "\n",
      "global acc: 0.5238095238095238\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 5\n",
      "\n",
      "global acc: 0.3333333333333333\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 6\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 7\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 8\n",
      "\n",
      "global acc: 0.42857142857142855\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 9\n",
      "\n",
      "global acc: 0.47619047619047616\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/mq592t7x67qbgfpvnk8cgrd80000gn/T/ipykernel_47785/982346476.py:32: DeprecationWarning: setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "  pred_classes[i] = [pred_class.flatten(), y_datapoints.flatten()[i]]\n",
      "/var/folders/tc/mq592t7x67qbgfpvnk8cgrd80000gn/T/ipykernel_47785/1130906350.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_pos / (true_pos + false_neg)\n"
     ]
    }
   ],
   "source": [
    "print(f\"K: 1\")\n",
    "\n",
    "for i, fold in enumerate(kc2_dataset_kfolds):\n",
    "    if(i == 0):\n",
    "        kc2_dataset_trainning = kc2_dataset_kfolds[i+1:].reshape((-1, kc2_dataset_kfolds.shape[-1]))\n",
    "    else:\n",
    "        kc2_dataset_trainning = np.vstack((kc2_dataset_kfolds[:i], kc2_dataset_kfolds[i+1:])).reshape((-1, kc2_dataset_kfolds.shape[-1]))\n",
    "\n",
    "    x_kc2_dataset_trainning = kc2_dataset_trainning[:, :-1]\n",
    "    y_kc2_dataset_trainning = kc2_dataset_trainning[:, [-1]]\n",
    "    x_kc2_dataset_test = fold[:, :-1]\n",
    "    y_kc2_dataset_test = fold[:, [-1]]\n",
    "\n",
    "    # checking if everything has the correct shape\n",
    "    # print(f\"iteration - {i+1}\")\n",
    "    # print(kc2_dataset_trainning.shape)\n",
    "    # print(x_kc2_dataset_trainning.shape)\n",
    "    # print(y_kc2_dataset_trainning.shape)\n",
    "    # print(x_kc2_dataset_test.shape)\n",
    "\n",
    "    knn_predictions = knn(x_kc2_dataset_trainning, y_kc2_dataset_trainning, 1, euclidian_distances, fold)\n",
    "\n",
    "    global_acc, class1_acc, class2_acc, precision, revoke = stats(knn_predictions[:, 0], knn_predictions[:, 1])\n",
    "\n",
    "    print(f\"STATS - fold {i}\\n\")\n",
    "    print(f\"global acc: {global_acc}\")\n",
    "    print(f\"class 1 acc: {class1_acc}\")\n",
    "    print(f\"class 2 acc: {class2_acc}\")\n",
    "    print(f\"precision: {class2_acc}\")\n",
    "    print(f\"revoke: {class2_acc}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1\n",
      "STATS - fold 0\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 1.0\n",
      "class 2 acc: 0.0\n",
      "precision: 0.0\n",
      "revoke: 0.0\n",
      "\n",
      "\n",
      "STATS - fold 1\n",
      "\n",
      "global acc: 0.47619047619047616\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 2\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 3\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 4\n",
      "\n",
      "global acc: 0.5238095238095238\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 5\n",
      "\n",
      "global acc: 0.3333333333333333\n",
      "class 1 acc: 0.0\n",
      "class 2 acc: 1.0\n",
      "precision: 1.0\n",
      "revoke: 1.0\n",
      "\n",
      "\n",
      "STATS - fold 6\n",
      "\n",
      "global acc: 0.42857142857142855\n",
      "class 1 acc: 1.0\n",
      "class 2 acc: 0.0\n",
      "precision: 0.0\n",
      "revoke: 0.0\n",
      "\n",
      "\n",
      "STATS - fold 7\n",
      "\n",
      "global acc: 0.42857142857142855\n",
      "class 1 acc: 1.0\n",
      "class 2 acc: 0.0\n",
      "precision: 0.0\n",
      "revoke: 0.0\n",
      "\n",
      "\n",
      "STATS - fold 8\n",
      "\n",
      "global acc: 0.5714285714285714\n",
      "class 1 acc: 1.0\n",
      "class 2 acc: 0.0\n",
      "precision: 0.0\n",
      "revoke: 0.0\n",
      "\n",
      "\n",
      "STATS - fold 9\n",
      "\n",
      "global acc: 0.5238095238095238\n",
      "class 1 acc: 1.0\n",
      "class 2 acc: 0.0\n",
      "precision: 0.0\n",
      "revoke: 0.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/mq592t7x67qbgfpvnk8cgrd80000gn/T/ipykernel_47785/982346476.py:32: DeprecationWarning: setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "  pred_classes[i] = [pred_class.flatten(), y_datapoints.flatten()[i]]\n",
      "/var/folders/tc/mq592t7x67qbgfpvnk8cgrd80000gn/T/ipykernel_47785/1130906350.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_pos / (true_pos + false_neg)\n"
     ]
    }
   ],
   "source": [
    "print(f\"K: 5\")\n",
    "\n",
    "for i, fold in enumerate(kc2_dataset_kfolds):\n",
    "    if(i == 0):\n",
    "        kc2_dataset_trainning = kc2_dataset_kfolds[i+1:].reshape((-1, kc2_dataset_kfolds.shape[-1]))\n",
    "    else:\n",
    "        kc2_dataset_trainning = np.vstack((kc2_dataset_kfolds[:i], kc2_dataset_kfolds[i+1:])).reshape((-1, kc2_dataset_kfolds.shape[-1]))\n",
    "\n",
    "    x_kc2_dataset_trainning = kc2_dataset_trainning[:, :-1]\n",
    "    y_kc2_dataset_trainning = kc2_dataset_trainning[:, [-1]]\n",
    "    x_kc2_dataset_test = fold[:, :-1]\n",
    "    y_kc2_dataset_test = fold[:, [-1]]\n",
    "\n",
    "    # checking if everything has the correct shape\n",
    "    # print(f\"iteration - {i+1}\")\n",
    "    # print(kc2_dataset_trainning.shape)\n",
    "    # print(x_kc2_dataset_trainning.shape)\n",
    "    # print(y_kc2_dataset_trainning.shape)\n",
    "    # print(x_kc2_dataset_test.shape)\n",
    "\n",
    "    knn_predictions = knn(x_kc2_dataset_trainning, y_kc2_dataset_trainning, 5, euclidian_distances, fold)\n",
    "\n",
    "    global_acc, class1_acc, class2_acc, precision, revoke = stats(knn_predictions[:, 0], knn_predictions[:, 1])\n",
    "\n",
    "    print(f\"STATS - fold {i}\\n\")\n",
    "    print(f\"global acc: {global_acc}\")\n",
    "    print(f\"class 1 acc: {class1_acc}\")\n",
    "    print(f\"class 2 acc: {class2_acc}\")\n",
    "    print(f\"precision: {class2_acc}\")\n",
    "    print(f\"revoke: {class2_acc}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
